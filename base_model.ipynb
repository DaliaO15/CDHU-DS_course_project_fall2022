{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d759580-f530-4f47-8ece-3a277a5a7413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTo be able to do transfer learning a base model needs to be trained\\n\\n1. Read a subset of FairFace data set. TODO: Read entire FairFace data set\\n2. Build base model\\n    2.1 Choose some model. TODO: Be specific about model chosen\\n    2.2 Random weights\\n    2.3 Input size as appropriate\\n3. Train base model\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "To be able to do transfer learning a base model needs to be trained\n",
    "\n",
    "1. Read a subset of FairFace data set. TODO: Read entire FairFace data set\n",
    "2. Build base model\n",
    "    2.1 Choose some model. TODO: Be specific about model chosen\n",
    "    2.2 Random weights\n",
    "    2.3 Input size as appropriate\n",
    "3. Train base model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "85b2ea73-1ba5-4a88-9f59-1c2422604920",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from fairness import fairnessMetrics as fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2740786-b451-4e75-a2dd-5ca1dd48ffd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-efficientnet\n",
      "  Downloading keras_efficientnet-0.1.4-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: keras-efficientnet\n",
      "Successfully installed keras-efficientnet-0.1.4\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8050efd4-b27f-41dd-b1b7-566ff3e67d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Replace with Christophs update code for loading data sets. \n",
    "def readImages(folderName, image_size, batch_size):\n",
    "    train_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "        folderName,\n",
    "        validation_split=0.2,\n",
    "        subset=\"training\",\n",
    "        seed=1337,\n",
    "        image_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        labels='inferred'\n",
    "    )\n",
    "    val_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "        folderName,\n",
    "        validation_split=0.2,\n",
    "        subset=\"validation\",\n",
    "        seed=1337,\n",
    "        image_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        labels='inferred'\n",
    "    )\n",
    "    return (train_ds, val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "08e0af77-6800-483e-91df-62fd539ddef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_20 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 134,264,641\n",
      "Trainable params: 134,264,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build base model\n",
    "# TODO: Choose appropriate model\n",
    "base_model = keras.applications.VGG16(\n",
    "    weights=None, \n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=True,\n",
    "    classes=1,\n",
    "    classifier_activation=\"sigmoid\",\n",
    ")\n",
    "\n",
    "# TODO: Remove classifying layers, will be added after being transferred\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5119e1e4-c90b-49e4-9eb7-bc1de998237b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "metrics_list = [\"accuracy\",\n",
    "                tf.keras.metrics.TruePositives(), \n",
    "                tf.keras.metrics.TrueNegatives(),\n",
    "                tf.keras.metrics.FalsePositives(), \n",
    "                tf.keras.metrics.FalseNegatives(), \n",
    "                fm.TruePositiveRate(),\n",
    "                fm.TrueNegativeRate(),\n",
    "                fm.FalsePositiveRate(),\n",
    "                fm.FalseNegativeRate(),\n",
    "                fm.PositivePredictedValue(),\n",
    "                fm.FalseDiscoveryRate(),\n",
    "                fm.NegativePredictedValue(),\n",
    "                fm.FalseOmissionRate(),\n",
    "                fm.BinaryDemographicParityDiff(),\n",
    "                fm.DemographicParity(),\n",
    "                fm.BinaryEqualizedOddsDiff(),\n",
    "                fm.BinaryProportionalParityDiff(),\n",
    "                fm.ProportionalParity(),\n",
    "                fm.BinaryPredictiveRateParityDiff(),\n",
    "                fm.PredictiveRateParity(),\n",
    "                fm.BinaryAccuracyParityDiff(),\n",
    "                fm.AccuracyParity(),\n",
    "                fm.BinaryFalseNegativeRateParityDiff(),\n",
    "                fm.BinaryFalsePositiveRateParityDiff(),\n",
    "                fm.BinaryNegativePredictiveRateParityDiff(),\n",
    "                fm.NegativePredictiveRateParity(),\n",
    "                fm.BinarySpecificityParityDiff()]\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-3) # TODO: Choose appropriate optimizer and learning_rate\n",
    "\n",
    "base_model.compile(optimizer=optimizer, \n",
    "                   loss=\"binary_crossentropy\", # TODO: look into this\n",
    "                   #loss=\"categorical_crossentropy\"\n",
    "                   metrics=metrics_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b19501-b8d0-44b1-b653-97d7931b1237",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Could be implemented?: Batch the data and use caching & prefetching to optimize loading speed\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6ee4f5-3cf7-414a-ab6e-1d69162c9ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DATA AUGMENTATION COULD BE ADDED HERE\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b8ff8efa-ecc8-4431-a26f-5ae9746da54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 files belonging to 2 classes.\n",
      "Using 160 files for training.\n",
      "Found 200 files belonging to 2 classes.\n",
      "Using 40 files for validation.\n"
     ]
    }
   ],
   "source": [
    "image_size = (224, 224) # This step should be standardizing, should be able to be changed to what is approptiate\n",
    "batch_size = 4\n",
    "data = readImages(\"FairFace_subset\", image_size, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0328401e-6dff-4831-9018-1547b19956d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6f3830e7-c306-477c-a670-ad99791de6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "40/40 [==============================] - 318s 7s/step - loss: 462.0170 - accuracy: 0.5500 - true_positives_294: 47.0000 - true_negatives_196: 41.0000 - false_positives_238: 39.0000 - false_negatives_252: 33.0000 - true_positive_rate: 0.5875 - true_negative_rate: 0.5125 - false_positive_rate: 0.4875 - false_negative_rate: 0.4125 - positive_predicted_value: 0.5465 - false_discovery_rate: 0.4535 - negative_predicted_value: 0.5541 - false_omission_rate: 0.4459 - binary_demographic_parity_diff: 12.0000 - demographic_parity: 86.0000 - binary_equalized_odds_diff: -0.0750 - binary_proportional_parity_diff: 0.0750 - proportional_parity: 0.5375 - binary_predictive_rate_parity_diff: -0.0075 - predictive_rate_parity: 0.5465 - binary_accuracy_parity_diff: 0.1000 - accuracy_parity: 0.5500 - false_negative_rate_parity_diff: 0.0750 - false_positive_rate_parity_diff: -0.0750 - binary_negative_predictive_rate_parity_diff: 0.0075 - negative_predictive_rate_parity: 0.5465 - binary_specificity_parity_diff: 0.0750 - val_loss: 0.6942 - val_accuracy: 0.5000 - val_true_positives_294: 20.0000 - val_true_negatives_196: 0.0000e+00 - val_false_positives_238: 20.0000 - val_false_negatives_252: 0.0000e+00 - val_true_positive_rate: 1.0000 - val_true_negative_rate: 0.0000e+00 - val_false_positive_rate: 1.0000 - val_false_negative_rate: 0.0000e+00 - val_positive_predicted_value: 0.5000 - val_false_discovery_rate: 0.5000 - val_negative_predicted_value: 0.0000e+00 - val_false_omission_rate: 0.0000e+00 - val_binary_demographic_parity_diff: 40.0000 - val_demographic_parity: 40.0000 - val_binary_equalized_odds_diff: -1.0000 - val_binary_proportional_parity_diff: 1.0000 - val_proportional_parity: 1.0000 - val_binary_predictive_rate_parity_diff: 0.5000 - val_predictive_rate_parity: 0.5000 - val_binary_accuracy_parity_diff: 0.0000e+00 - val_accuracy_parity: 0.5000 - val_false_negative_rate_parity_diff: 1.0000 - val_false_positive_rate_parity_diff: -1.0000 - val_binary_negative_predictive_rate_parity_diff: -0.5000 - val_negative_predictive_rate_parity: 0.5000 - val_binary_specificity_parity_diff: 1.0000\n",
      "Epoch 2/5\n",
      "40/40 [==============================] - 264s 7s/step - loss: 0.6962 - accuracy: 0.4875 - true_positives_294: 65.0000 - true_negatives_196: 13.0000 - false_positives_238: 67.0000 - false_negatives_252: 15.0000 - true_positive_rate: 0.8125 - true_negative_rate: 0.1625 - false_positive_rate: 0.8375 - false_negative_rate: 0.1875 - positive_predicted_value: 0.4924 - false_discovery_rate: 0.5076 - negative_predicted_value: 0.4643 - false_omission_rate: 0.5357 - binary_demographic_parity_diff: 104.0000 - demographic_parity: 132.0000 - binary_equalized_odds_diff: -0.6500 - binary_proportional_parity_diff: 0.6500 - proportional_parity: 0.8250 - binary_predictive_rate_parity_diff: 0.0281 - predictive_rate_parity: 0.4924 - binary_accuracy_parity_diff: -0.0250 - accuracy_parity: 0.4875 - false_negative_rate_parity_diff: 0.6500 - false_positive_rate_parity_diff: -0.6500 - binary_negative_predictive_rate_parity_diff: -0.0281 - negative_predictive_rate_parity: 0.4924 - binary_specificity_parity_diff: 0.6500 - val_loss: 0.6947 - val_accuracy: 0.5000 - val_true_positives_294: 20.0000 - val_true_negatives_196: 0.0000e+00 - val_false_positives_238: 20.0000 - val_false_negatives_252: 0.0000e+00 - val_true_positive_rate: 1.0000 - val_true_negative_rate: 0.0000e+00 - val_false_positive_rate: 1.0000 - val_false_negative_rate: 0.0000e+00 - val_positive_predicted_value: 0.5000 - val_false_discovery_rate: 0.5000 - val_negative_predicted_value: 0.0000e+00 - val_false_omission_rate: 0.0000e+00 - val_binary_demographic_parity_diff: 40.0000 - val_demographic_parity: 40.0000 - val_binary_equalized_odds_diff: -1.0000 - val_binary_proportional_parity_diff: 1.0000 - val_proportional_parity: 1.0000 - val_binary_predictive_rate_parity_diff: 0.5000 - val_predictive_rate_parity: 0.5000 - val_binary_accuracy_parity_diff: 0.0000e+00 - val_accuracy_parity: 0.5000 - val_false_negative_rate_parity_diff: 1.0000 - val_false_positive_rate_parity_diff: -1.0000 - val_binary_negative_predictive_rate_parity_diff: -0.5000 - val_negative_predictive_rate_parity: 0.5000 - val_binary_specificity_parity_diff: 1.0000\n",
      "Epoch 3/5\n",
      "40/40 [==============================] - 267s 7s/step - loss: 0.6971 - accuracy: 0.4625 - true_positives_294: 65.0000 - true_negatives_196: 9.0000 - false_positives_238: 71.0000 - false_negatives_252: 15.0000 - true_positive_rate: 0.8125 - true_negative_rate: 0.1125 - false_positive_rate: 0.8875 - false_negative_rate: 0.1875 - positive_predicted_value: 0.4779 - false_discovery_rate: 0.5221 - negative_predicted_value: 0.3750 - false_omission_rate: 0.6250 - binary_demographic_parity_diff: 112.0000 - demographic_parity: 136.0000 - binary_equalized_odds_diff: -0.7000 - binary_proportional_parity_diff: 0.7000 - proportional_parity: 0.8500 - binary_predictive_rate_parity_diff: 0.1029 - predictive_rate_parity: 0.4779 - binary_accuracy_parity_diff: -0.0750 - accuracy_parity: 0.4625 - false_negative_rate_parity_diff: 0.7000 - false_positive_rate_parity_diff: -0.7000 - binary_negative_predictive_rate_parity_diff: -0.1029 - negative_predictive_rate_parity: 0.4779 - binary_specificity_parity_diff: 0.7000 - val_loss: 0.6932 - val_accuracy: 0.5000 - val_true_positives_294: 20.0000 - val_true_negatives_196: 0.0000e+00 - val_false_positives_238: 20.0000 - val_false_negatives_252: 0.0000e+00 - val_true_positive_rate: 1.0000 - val_true_negative_rate: 0.0000e+00 - val_false_positive_rate: 1.0000 - val_false_negative_rate: 0.0000e+00 - val_positive_predicted_value: 0.5000 - val_false_discovery_rate: 0.5000 - val_negative_predicted_value: 0.0000e+00 - val_false_omission_rate: 0.0000e+00 - val_binary_demographic_parity_diff: 40.0000 - val_demographic_parity: 40.0000 - val_binary_equalized_odds_diff: -1.0000 - val_binary_proportional_parity_diff: 1.0000 - val_proportional_parity: 1.0000 - val_binary_predictive_rate_parity_diff: 0.5000 - val_predictive_rate_parity: 0.5000 - val_binary_accuracy_parity_diff: 0.0000e+00 - val_accuracy_parity: 0.5000 - val_false_negative_rate_parity_diff: 1.0000 - val_false_positive_rate_parity_diff: -1.0000 - val_binary_negative_predictive_rate_parity_diff: -0.5000 - val_negative_predictive_rate_parity: 0.5000 - val_binary_specificity_parity_diff: 1.0000\n",
      "Epoch 4/5\n",
      "40/40 [==============================] - 267s 7s/step - loss: 0.6944 - accuracy: 0.4625 - true_positives_294: 11.0000 - true_negatives_196: 63.0000 - false_positives_238: 17.0000 - false_negatives_252: 69.0000 - true_positive_rate: 0.1375 - true_negative_rate: 0.7875 - false_positive_rate: 0.2125 - false_negative_rate: 0.8625 - positive_predicted_value: 0.3929 - false_discovery_rate: 0.6071 - negative_predicted_value: 0.4773 - false_omission_rate: 0.5227 - binary_demographic_parity_diff: -104.0000 - demographic_parity: 28.0000 - binary_equalized_odds_diff: 0.6500 - binary_proportional_parity_diff: -0.6500 - proportional_parity: 0.1750 - binary_predictive_rate_parity_diff: -0.0844 - predictive_rate_parity: 0.3929 - binary_accuracy_parity_diff: -0.0750 - accuracy_parity: 0.4625 - false_negative_rate_parity_diff: -0.6500 - false_positive_rate_parity_diff: 0.6500 - binary_negative_predictive_rate_parity_diff: 0.0844 - negative_predictive_rate_parity: 0.3929 - binary_specificity_parity_diff: -0.6500 - val_loss: 0.6932 - val_accuracy: 0.5000 - val_true_positives_294: 0.0000e+00 - val_true_negatives_196: 20.0000 - val_false_positives_238: 0.0000e+00 - val_false_negatives_252: 20.0000 - val_true_positive_rate: 0.0000e+00 - val_true_negative_rate: 1.0000 - val_false_positive_rate: 0.0000e+00 - val_false_negative_rate: 1.0000 - val_positive_predicted_value: 0.0000e+00 - val_false_discovery_rate: 0.0000e+00 - val_negative_predicted_value: 0.5000 - val_false_omission_rate: 0.5000 - val_binary_demographic_parity_diff: -40.0000 - val_demographic_parity: 1.0000e-07 - val_binary_equalized_odds_diff: 1.0000 - val_binary_proportional_parity_diff: -1.0000 - val_proportional_parity: 0.0000e+00 - val_binary_predictive_rate_parity_diff: -0.5000 - val_predictive_rate_parity: 0.0000e+00 - val_binary_accuracy_parity_diff: 0.0000e+00 - val_accuracy_parity: 0.5000 - val_false_negative_rate_parity_diff: -1.0000 - val_false_positive_rate_parity_diff: 1.0000 - val_binary_negative_predictive_rate_parity_diff: 0.5000 - val_negative_predictive_rate_parity: 0.0000e+00 - val_binary_specificity_parity_diff: -1.0000\n",
      "Epoch 5/5\n",
      "40/40 [==============================] - 266s 7s/step - loss: 0.6935 - accuracy: 0.5000 - true_positives_294: 0.0000e+00 - true_negatives_196: 80.0000 - false_positives_238: 0.0000e+00 - false_negatives_252: 80.0000 - true_positive_rate: 0.0000e+00 - true_negative_rate: 1.0000 - false_positive_rate: 0.0000e+00 - false_negative_rate: 1.0000 - positive_predicted_value: 0.0000e+00 - false_discovery_rate: 0.0000e+00 - negative_predicted_value: 0.5000 - false_omission_rate: 0.5000 - binary_demographic_parity_diff: -160.0000 - demographic_parity: 1.0000e-07 - binary_equalized_odds_diff: 1.0000 - binary_proportional_parity_diff: -1.0000 - proportional_parity: 0.0000e+00 - binary_predictive_rate_parity_diff: -0.5000 - predictive_rate_parity: 0.0000e+00 - binary_accuracy_parity_diff: 0.0000e+00 - accuracy_parity: 0.5000 - false_negative_rate_parity_diff: -1.0000 - false_positive_rate_parity_diff: 1.0000 - binary_negative_predictive_rate_parity_diff: 0.5000 - negative_predictive_rate_parity: 0.0000e+00 - binary_specificity_parity_diff: -1.0000 - val_loss: 0.6932 - val_accuracy: 0.5000 - val_true_positives_294: 0.0000e+00 - val_true_negatives_196: 20.0000 - val_false_positives_238: 0.0000e+00 - val_false_negatives_252: 20.0000 - val_true_positive_rate: 0.0000e+00 - val_true_negative_rate: 1.0000 - val_false_positive_rate: 0.0000e+00 - val_false_negative_rate: 1.0000 - val_positive_predicted_value: 0.0000e+00 - val_false_discovery_rate: 0.0000e+00 - val_negative_predicted_value: 0.5000 - val_false_omission_rate: 0.5000 - val_binary_demographic_parity_diff: -40.0000 - val_demographic_parity: 1.0000e-07 - val_binary_equalized_odds_diff: 1.0000 - val_binary_proportional_parity_diff: -1.0000 - val_proportional_parity: 0.0000e+00 - val_binary_predictive_rate_parity_diff: -0.5000 - val_predictive_rate_parity: 0.0000e+00 - val_binary_accuracy_parity_diff: 0.0000e+00 - val_accuracy_parity: 0.5000 - val_false_negative_rate_parity_diff: -1.0000 - val_false_positive_rate_parity_diff: 1.0000 - val_binary_negative_predictive_rate_parity_diff: 0.5000 - val_negative_predictive_rate_parity: 0.0000e+00 - val_binary_specificity_parity_diff: -1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa8699e9b50>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 5\n",
    "base_model.fit(data[0], epochs=epochs, validation_data=data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a40e0e86-52a8-422d-807b-bd250e21483b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_base_model/assets\n"
     ]
    }
   ],
   "source": [
    "base_model.save('saved_base_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
